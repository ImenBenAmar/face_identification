{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ddb291c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucun visage détecté dans l'image : .\\data\\Adriana Lima\\Adriana Lima30_153.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Alex Lawther\\Alex Lawther112_12.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Alex Lawther\\Alex Lawther135_28.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Alex Lawther\\Alex Lawther188_66.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Alex Lawther\\Alex Lawther194_68.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Alex Lawther\\Alex Lawther91_144.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Alvaro Morte\\Alvaro Morte142_179.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Alvaro Morte\\Alvaro Morte159_197.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Alvaro Morte\\Alvaro Morte209_219.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Alvaro Morte\\Alvaro Morte215_222.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Alvaro Morte\\Alvaro Morte31_241.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Alvaro Morte\\Alvaro Morte7_267.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\alycia dabnem carey\\alycia dabnem carey124_25.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\alycia dabnem carey\\alycia dabnem carey71_187.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\amber heard\\amber heard203_313.jpg\n",
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucun visage détecté dans l'image : .\\data\\Dwayne Johnson\\Dwayne Johnson117_1573.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Dwayne Johnson\\Dwayne Johnson41_1667.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Dwayne Johnson\\Dwayne Johnson59_1679.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Dwayne Johnson\\Dwayne Johnson98_1698.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Eliza Taylor\\Eliza Taylor229_796.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Elizabeth Lail\\Elizabeth Lail147_1088.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Elizabeth Lail\\Elizabeth Lail47_1168.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Elizabeth Lail\\Elizabeth Lail5_1171.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\elizabeth olsen\\elizabeth olsen195_1203.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\elizabeth olsen\\elizabeth olsen30_1264.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\elizabeth olsen\\elizabeth olsen83_1316.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\ellen page\\ellen page226_1437.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\ellen page\\ellen page31_1464.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\ellen page\\ellen page43_1476.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\ellen page\\ellen page74_1503.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\elon musk\\elon musk145_1549.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\elon musk\\elon musk41_1621.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\elon musk\\elon musk53_1631.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\elon musk\\elon musk72_1646.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\elon musk\\elon musk74_1647.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Emilia Clarke\\Emilia Clarke153_910.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Emilia Clarke\\Emilia Clarke210_962.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Emilia Clarke\\Emilia Clarke78_1050.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Emma Stone\\Emma Stone220_1755.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Emma Stone\\Emma Stone44_1788.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Emma Stone\\Emma Stone72_1816.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Emma Watson\\Emma Watson215_1950.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Emma Watson\\Emma Watson37_1993.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Emma Watson\\Emma Watson80_2033.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\gal gadot\\gal gadot108_1668.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\gal gadot\\gal gadot46_1807.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\gal gadot\\gal gadot88_1843.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\grant gustin\\grant gustin106_1868.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\grant gustin\\grant gustin163_1903.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\grant gustin\\grant gustin221_1953.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\grant gustin\\grant gustin2_1933.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Gwyneth Paltrow\\Gwyneth Paltrow110_2068.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Gwyneth Paltrow\\Gwyneth Paltrow242_2184.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Gwyneth Paltrow\\Gwyneth Paltrow33_2195.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Henry Cavil\\Henry Cavil189_1157.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Henry Cavil\\Henry Cavil204_1174.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Henry Cavil\\Henry Cavil234_1192.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Hugh Jackman\\Hugh Jackman118_1288.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Hugh Jackman\\Hugh Jackman34_1406.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Hugh Jackman\\Hugh Jackman99_1452.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Irina Shayk\\Irina Shayk135_2274.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Irina Shayk\\Irina Shayk27_2343.jpg\n",
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucun visage détecté dans l'image : .\\data\\Logan Lerman\\Logan Lerman191_2365.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Logan Lerman\\Logan Lerman80_2477.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Logan Lerman\\Logan Lerman84_2482.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Madelaine Petsch\\Madelaine Petsch119_2883.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Madelaine Petsch\\Madelaine Petsch24_2983.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Madelaine Petsch\\Madelaine Petsch74_3030.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Maisie Williams\\Maisie Williams5_2646.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Maisie Williams\\Maisie Williams66_2658.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\margot robbie\\margot robbie108_3065.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\margot robbie\\margot robbie120_3083.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\margot robbie\\margot robbie241_3199.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\margot robbie\\margot robbie86_3265.jpg\n",
      
     
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucun visage détecté dans l'image : .\\data\\Taylor Swift\\Taylor Swift140_4571.jpg\n",
      "Aucun visage détecté dans l'image : .\\data\\Taylor Swift\\Taylor Swift144_4572.jpg\n",
      
      "Embeddings et étiquettes sauvegardés avec succès.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Chemin du répertoire contenant les dossiers d'images\n",
    "base_directory = r\".\\data\"\n",
    "\n",
    "# Initialisation des modèles dlib\n",
    "pose_predictor_68_point = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "face_encoder = dlib.face_recognition_model_v1(\"dlib_face_recognition_resnet_model_v1.dat\")\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Initialiser les listes pour stocker les embeddings et les étiquettes\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Image non lue : {image_path}\")\n",
    "    return image\n",
    "\n",
    "def extract_face_embeddings(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector(gray)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    face = faces[0]\n",
    "    shape = pose_predictor_68_point(image, face)\n",
    "    face_descriptor = face_encoder.compute_face_descriptor(image, shape)\n",
    "    return np.array(face_descriptor)\n",
    "\n",
    "# Créer un dictionnaire pour attribuer un ID unique à chaque personne sans trier\n",
    "person_names = os.listdir(base_directory)  # Obtenir les noms de dossiers sans les trier\n",
    "person_ids = {name: idx + 1 for idx, name in enumerate(person_names)}\n",
    "\n",
    "# Lire les images à partir des répertoires\n",
    "for person_name, person_id in person_ids.items():\n",
    "    person_folder = os.path.join(base_directory, person_name)\n",
    "    if os.path.isdir(person_folder):\n",
    "        for image_name in os.listdir(person_folder):\n",
    "            image_path = os.path.join(person_folder, image_name)\n",
    "            image = load_image(image_path)\n",
    "            if image is not None:\n",
    "                face_embedding = extract_face_embeddings(image)\n",
    "                if face_embedding is not None:\n",
    "                    embeddings.append(face_embedding)\n",
    "                    labels.append(person_id)  # Utiliser l'ID de la personne comme étiquette\n",
    "                else:\n",
    "                    print(f\"Aucun visage détecté dans l'image : {image_path}\")\n",
    "\n",
    "# Convertir les données en numpy arrays\n",
    "embeddings = np.array(embeddings)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Enregistrer les embeddings et les étiquettes\n",
    "with open('embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump((embeddings, labels), f)\n",
    "\n",
    "print(\"Embeddings et étiquettes sauvegardés avec succès.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a93ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Charger les embeddings et les étiquettes\n",
    "with open('embeddings.pkl', 'rb') as f:\n",
    "    embeddings, labels = pickle.load(f)\n",
    "\n",
    "# Encoder les étiquettes\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "(train_data, test_data, train_labels, test_labels) = train_test_split(embeddings, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraîner un classificateur SVM\n",
    "clf = SVC(kernel='linear', probability=True)\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "# Enregistrer le classificateur et le LabelEncoder\n",
    "with open('classifier.pkl', 'wb') as f:\n",
    "    pickle.dump((clf, le), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1146a56",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Charger le classificateur et le LabelEncoder\n",
    "with open('classifier.pkl', 'rb') as f:\n",
    "    clf, le = pickle.load(f)\n",
    "\n",
    "# Charger les embeddings et les étiquettes\n",
    "with open('embeddings.pkl', 'rb') as f:\n",
    "    embeddings, labels = pickle.load(f)\n",
    "\n",
    "# Encoder les étiquettes\n",
    "labels = le.transform(labels)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "(train_data, test_data, train_labels, test_labels) = train_test_split(embeddings, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Effectuer des prédictions sur l'ensemble de test\n",
    "predictions = clf.predict(test_data)\n",
    "\n",
    "# Calculer l'accuracy totale\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy totale: {accuracy:.2f}\")\n",
    "\n",
    "# Générer un rapport de classification pour afficher la précision de chaque personne (chaque ID)\n",
    "report = classification_report(test_labels, predictions, target_names=[str(i) for i in le.classes_])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe654cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom: Adriana Lima, ID: 1\n",
      "Nom: Alex Lawther, ID: 2\n",
      "Nom: Alexandra Daddario, ID: 3\n",
      "Nom: Alvaro Morte, ID: 4\n",
      "Nom: alycia dabnem carey, ID: 5\n",
      "Nom: Amanda Crew, ID: 6\n",
      "Nom: amber heard, ID: 7\n",
      "Nom: Andy Samberg, ID: 8\n",
      "Nom: Anne Hathaway, ID: 9\n",
      "Nom: Anthony Mackie, ID: 10\n",
      "Nom: Avril Lavigne, ID: 11\n",
      "Nom: barack obama, ID: 12\n",
      "Nom: barbara palvin, ID: 13\n",
      "Nom: Ben Affleck, ID: 14\n",
      "Nom: Bill Gates, ID: 15\n",
      "Nom: Bobby Morley, ID: 16\n",
      "Nom: Brenton Thwaites, ID: 17\n",
      "Nom: Brian J. Smith, ID: 18\n",
      "Nom: Brie Larson, ID: 19\n",
      "Nom: camila mendes, ID: 20\n",
      "Nom: Chris Evans, ID: 21\n",
      "Nom: Chris Hemsworth, ID: 22\n",
      "Nom: Chris Pratt, ID: 23\n",
      "Nom: Christian Bale, ID: 24\n",
      "Nom: Cristiano Ronaldo, ID: 25\n",
      "Nom: Danielle Panabaker, ID: 26\n",
      "Nom: Dominic Purcell, ID: 27\n",
      "Nom: Dwayne Johnson, ID: 28\n",
      "Nom: Eliza Taylor, ID: 29\n",
      "Nom: Elizabeth Lail, ID: 30\n",
      "Nom: elizabeth olsen, ID: 31\n",
      "Nom: ellen page, ID: 32\n",
      "Nom: elon musk, ID: 33\n",
      "Nom: Emilia Clarke, ID: 34\n",
      "Nom: Emma Stone, ID: 35\n",
      "Nom: Emma Watson, ID: 36\n",
      "Nom: gal gadot, ID: 37\n",
      "Nom: grant gustin, ID: 38\n",
      "Nom: Gwyneth Paltrow, ID: 39\n",
      "Nom: Henry Cavil, ID: 40\n",
      "Nom: Hugh Jackman, ID: 41\n",
      "Nom: Inbar Lavi, ID: 42\n",
      "Nom: Irina Shayk, ID: 43\n",
      "Nom: Jake Mcdorman, ID: 44\n",
      "Nom: Jason Momoa, ID: 45\n",
      "Nom: jeff bezos, ID: 46\n",
      "Nom: Jennifer Lawrence, ID: 47\n",
      "Nom: Jeremy Renner, ID: 48\n",
      "Nom: Jessica Barden, ID: 49\n",
      "Nom: Jimmy Fallon, ID: 50\n",
      "Nom: Johnny Depp, ID: 51\n",
      "Nom: Josh Radnor, ID: 52\n",
      "Nom: Katharine Mcphee, ID: 53\n",
      "Nom: Katherine Langford, ID: 54\n",
      "Nom: Keanu Reeves, ID: 55\n",
      "Nom: kiernen shipka, ID: 56\n",
      "Nom: Krysten Ritter, ID: 57\n",
      "Nom: Leonardo DiCaprio, ID: 58\n",
      "Nom: Lili Reinhart, ID: 59\n",
      "Nom: Lindsey Morgan, ID: 60\n",
      "Nom: Lionel Messi, ID: 61\n",
      "Nom: Logan Lerman, ID: 62\n",
      "Nom: Madelaine Petsch, ID: 63\n",
      "Nom: Maisie Williams, ID: 64\n",
      "Nom: margot robbie, ID: 65\n",
      "Nom: Maria Pedraza, ID: 66\n",
      "Nom: Marie Avgeropoulos, ID: 67\n",
      "Nom: Mark Ruffalo, ID: 68\n",
      "Nom: Mark Zuckerberg, ID: 69\n",
      "Nom: Megan Fox, ID: 70\n",
      "Nom: melissa fumero, ID: 71\n",
      "Nom: Miley Cyrus, ID: 72\n",
      "Nom: Millie Bobby Brown, ID: 73\n",
      "Nom: Morena Baccarin, ID: 74\n",
      "Nom: Morgan Freeman, ID: 75\n",
      "Nom: Nadia Hilker, ID: 76\n",
      "Nom: Natalie Dormer, ID: 77\n",
      "Nom: Natalie Portman, ID: 78\n",
      "Nom: Neil Patrick Harris, ID: 79\n",
      "Nom: Pedro Alonso, ID: 80\n",
      "Nom: Penn Badgley, ID: 81\n",
      "Nom: Rami Malek, ID: 82\n",
      "Nom: Rebecca Ferguson, ID: 83\n",
      "Nom: Richard Harmon, ID: 84\n",
      "Nom: Rihanna, ID: 85\n",
      "Nom: Robert De Niro, ID: 86\n",
      "Nom: Robert Downey Jr, ID: 87\n",
      "Nom: Sarah Wayne Callies, ID: 88\n",
      "Nom: scarlett johansson, ID: 89\n",
      "Nom: Selena Gomez, ID: 90\n",
      "Nom: Shakira Isabel Mebarak, ID: 91\n",
      "Nom: Sophie Turner, ID: 92\n",
      "Nom: Stephen Amell, ID: 93\n",
      "Nom: Taylor Swift, ID: 94\n",
      "Nom: Tom Cruise, ID: 95\n",
      "Nom: tom ellis, ID: 96\n",
      "Nom: Tom Hardy, ID: 97\n",
      "Nom: Tom Hiddleston, ID: 98\n",
      "Nom: Tom Holland, ID: 99\n",
      "Nom: Tuppence Middleton, ID: 100\n",
      "Nom: Ursula Corbero, ID: 101\n",
      "Nom: Wentworth Miller, ID: 102\n",
      "Nom: Zac Efron, ID: 103\n",
      "Nom: Zendaya, ID: 104\n",
      "Nom: Zoe Saldana, ID: 105\n"
     ]
    }
   ],
   "source": [
    "# Afficher chaque nom avec son ID\n",
    "for person_name, person_id in person_ids.items():\n",
    "    print(f\"Nom: {person_name}, ID: {person_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d6d4f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Charger le classificateur et le LabelEncoder\n",
    "with open('classifier.pkl', 'rb') as f:\n",
    "    clf, le = pickle.load(f)\n",
    "\n",
    "# Initialiser les modèles dlib\n",
    "pose_predictor_68_point = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "face_encoder = dlib.face_recognition_model_v1(\"dlib_face_recognition_resnet_model_v1.dat\")\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Définir le seuil de confiance\n",
    "CONFIDENCE_THRESHOLD = 0.2\n",
    "\n",
    "# Fonction pour extraire les embeddings de visage avec dlib\n",
    "def extract_face_embeddings(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector(gray, 1)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        face = faces[0]\n",
    "        shape = pose_predictor_68_point(image, face)\n",
    "        face_descriptor = face_encoder.compute_face_descriptor(image, shape)\n",
    "        return np.array(face_descriptor)\n",
    "\n",
    "# Capture d'images depuis la caméra\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Réduire la taille de la frame pour un traitement plus rapide\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "    face_embedding = extract_face_embeddings(small_frame)\n",
    "    if face_embedding is not None:\n",
    "        face_embedding = face_embedding.reshape(1, -1)\n",
    "        predictions = clf.predict_proba(face_embedding)[0]\n",
    "        max_index = np.argmax(predictions)\n",
    "        if predictions[max_index] > CONFIDENCE_THRESHOLD:\n",
    "            person_id = le.inverse_transform([max_index])[0]\n",
    "            label_text = f\"ID: {person_id}\"\n",
    "        else:\n",
    "            label_text = \"Inconnu\"\n",
    "        # Afficher le résultat sur la frame originale\n",
    "        cv2.putText(frame, label_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Facial Recognition', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ba3912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy totale: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        46\n",
      "           2       1.00      1.00      1.00        34\n",
      "           3       1.00      0.98      0.99        46\n",
      "           4       0.94      1.00      0.97        17\n",
      "           5       0.95      1.00      0.97        36\n",
      "           6       1.00      1.00      1.00        27\n",
      "           7       1.00      0.97      0.99        39\n",
      "           8       1.00      1.00      1.00        40\n",
      "           9       1.00      1.00      1.00        46\n",
      "          10       1.00      0.96      0.98        24\n",
      "          11       0.95      1.00      0.98        20\n",
      "          12       1.00      1.00      1.00        20\n",
      "          13       1.00      1.00      1.00        42\n",
      "          14       1.00      1.00      1.00        26\n",
      "          15       0.95      1.00      0.98        20\n",
      "          16       1.00      1.00      1.00        29\n",
      "          17       1.00      1.00      1.00        36\n",
      "          18       1.00      1.00      1.00        23\n",
      "          19       0.95      0.97      0.96        39\n",
      "          20       1.00      0.97      0.98        29\n",
      "          21       1.00      0.96      0.98        27\n",
      "          22       1.00      0.97      0.98        31\n",
      "          23       1.00      1.00      1.00        45\n",
      "          24       1.00      1.00      1.00        23\n",
      "          25       1.00      0.94      0.97        18\n",
      "          26       1.00      1.00      1.00        50\n",
      "          27       1.00      1.00      1.00        28\n",
      "          28       1.00      1.00      1.00        21\n",
      "          29       1.00      0.96      0.98        27\n",
      "          30       0.96      0.96      0.96        27\n",
      "          31       0.96      1.00      0.98        43\n",
      "          32       1.00      0.95      0.98        43\n",
      "          33       1.00      1.00      1.00        21\n",
      "          34       0.96      0.98      0.97        47\n",
      "          35       1.00      0.93      0.96        28\n",
      "          36       0.94      0.94      0.94        32\n",
      "          37       0.94      0.98      0.96        47\n",
      "          38       1.00      1.00      1.00        45\n",
      "          39       1.00      1.00      1.00        32\n",
      "          40       1.00      0.98      0.99        45\n",
      "          41       1.00      1.00      1.00        35\n",
      "          42       1.00      1.00      1.00        26\n",
      "          43       1.00      0.93      0.96        29\n",
      "          44       1.00      1.00      1.00        28\n",
      "          45       0.97      1.00      0.99        38\n",
      "          46       1.00      1.00      1.00        20\n",
      "          47       0.95      0.98      0.96        42\n",
      "          48       1.00      0.97      0.99        39\n",
      "          49       1.00      1.00      1.00        23\n",
      "          50       1.00      0.94      0.97        18\n",
      "          51       0.91      1.00      0.96        43\n",
      "          52       1.00      1.00      1.00        26\n",
      "          53       1.00      1.00      1.00        36\n",
      "          54       0.98      1.00      0.99        48\n",
      "          55       1.00      1.00      1.00        32\n",
      "          56       1.00      0.97      0.99        39\n",
      "          57       1.00      1.00      1.00        36\n",
      "          58       1.00      0.98      0.99        49\n",
      "          59       1.00      0.92      0.96        38\n",
      "          60       1.00      0.93      0.96        40\n",
      "          61       1.00      1.00      1.00        15\n",
      "          62       1.00      0.98      0.99        43\n",
      "          63       0.95      0.97      0.96        38\n",
      "          64       0.98      0.96      0.97        49\n",
      "          65       0.95      1.00      0.98        40\n",
      "          66       0.96      0.96      0.96        24\n",
      "          67       1.00      1.00      1.00        32\n",
      "          68       1.00      1.00      1.00        33\n",
      "          69       1.00      1.00      1.00        23\n",
      "          70       0.95      0.98      0.96        41\n",
      "          71       1.00      1.00      1.00        31\n",
      "          72       0.97      1.00      0.98        32\n",
      "          73       0.94      1.00      0.97        34\n",
      "          74       1.00      1.00      1.00        29\n",
      "          75       1.00      1.00      1.00        12\n",
      "          76       1.00      1.00      1.00        25\n",
      "          77       1.00      0.97      0.98        33\n",
      "          78       1.00      0.98      0.99        41\n",
      "          79       1.00      1.00      1.00        23\n",
      "          80       1.00      1.00      1.00        23\n",
      "          81       1.00      1.00      1.00        26\n",
      "          82       1.00      1.00      1.00        25\n",
      "          83       1.00      0.97      0.99        38\n",
      "          84       1.00      1.00      1.00        20\n",
      "          85       1.00      1.00      1.00        26\n",
      "          86       0.97      0.97      0.97        33\n",
      "          87       0.94      1.00      0.97        32\n",
      "          88       1.00      0.97      0.98        31\n",
      "          89       1.00      0.97      0.99        40\n",
      "          90       0.98      1.00      0.99        47\n",
      "          91       1.00      1.00      1.00        29\n",
      "          92       1.00      1.00      1.00        45\n",
      "          93       1.00      1.00      1.00        28\n",
      "          94       0.95      0.95      0.95        21\n",
      "          95       1.00      1.00      1.00        30\n",
      "          96       1.00      1.00      1.00        27\n",
      "          97       0.97      0.97      0.97        36\n",
      "          98       1.00      1.00      1.00        28\n",
      "          99       0.88      0.97      0.92        36\n",
      "         100       1.00      0.97      0.98        29\n",
      "         101       0.97      1.00      0.98        28\n",
      "         102       0.97      0.97      0.97        34\n",
      "         103       0.97      1.00      0.99        37\n",
      "         104       1.00      1.00      1.00        42\n",
      "         105       1.00      0.98      0.99        41\n",
      "\n",
      "    accuracy                           0.99      3434\n",
      "   macro avg       0.99      0.99      0.99      3434\n",
      "weighted avg       0.99      0.99      0.99      3434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Charger le classificateur et le LabelEncoder\n",
    "with open('classifier.pkl', 'rb') as f:\n",
    "    clf, le = pickle.load(f)\n",
    "\n",
    "# Charger les embeddings et les étiquettes\n",
    "with open('embeddings.pkl', 'rb') as f:\n",
    "    embeddings, labels = pickle.load(f)\n",
    "\n",
    "# Encoder les étiquettes\n",
    "labels = le.transform(labels)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "(train_data, test_data, train_labels, test_labels) = train_test_split(embeddings, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Effectuer des prédictions sur l'ensemble de test\n",
    "predictions = clf.predict(test_data)\n",
    "\n",
    "# Calculer l'accuracy totale\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"Accuracy totale: {accuracy:.2f}\")\n",
    "\n",
    "# Générer un rapport de classification pour afficher la précision de chaque personne (chaque ID)\n",
    "report = classification_report(test_labels, predictions, target_names=[str(i) for i in le.classes_])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b027fc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID spécifié et ses données supprimés et le modèle mis à jour avec succès.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger les embeddings et les étiquettes\n",
    "with open('embeddings.pkl', 'rb') as f:\n",
    "    embeddings, labels = pickle.load(f)\n",
    "\n",
    "# Convertir les étiquettes en tableau NumPy si ce n'est pas déjà fait\n",
    "labels = np.array(labels)\n",
    "\n",
    "# ID de la personne à supprimer\n",
    "id_to_remove = 106 # Remplacez par l'ID que vous souhaitez supprimer\n",
    "\n",
    "# Filtrer les embeddings et les étiquettes pour supprimer les données de l'ID spécifié\n",
    "indices_to_keep = np.where(labels != id_to_remove)[0]\n",
    "filtered_embeddings = embeddings[indices_to_keep]\n",
    "filtered_labels = labels[indices_to_keep]\n",
    "\n",
    "# Enregistrer les embeddings et les étiquettes filtrés\n",
    "with open('embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump((filtered_embeddings, filtered_labels), f)\n",
    "\n",
    "# Encoder les étiquettes\n",
    "le = LabelEncoder()\n",
    "filtered_labels = le.fit_transform(filtered_labels)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "(train_data, test_data, train_labels, test_labels) = train_test_split(filtered_embeddings, filtered_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraîner un classificateur SVM\n",
    "clf = SVC(kernel='linear', probability=True)\n",
    "clf.fit(train_data, train_labels)\n",
    "\n",
    "# Enregistrer le classificateur et le LabelEncoder\n",
    "with open('classifier.pkl', 'wb') as f:\n",
    "    pickle.dump((clf, le), f)\n",
    "\n",
    "print(\"ID spécifié et ses données supprimés et le modèle mis à jour avec succès.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5329f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
